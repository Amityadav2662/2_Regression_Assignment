{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498bd7b5-9f4e-43a0-a8e8-d1b80a80f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it\n",
    "# represent?\n",
    "Ans.\n",
    "R-squared, often denoted as R², is a measure that indicates the proportion of the variance in the dependent \n",
    "variable (the outcome) explained by the independent variable(s) in a linear regression model.\n",
    "\n",
    "Formula of R-Squared is:\n",
    "    1 - Sum of square resuidual/Sum of total square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5132a324-8107-40a1-928f-febdbf48d8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight  Height\n",
       "0      45     120\n",
       "1      58     135\n",
       "2      48     123\n",
       "3      60     145\n",
       "4      70     160"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('height-weight.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc1406e-c7dc-409c-a472-1b3ab08c80e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b793715-afd7-4879-bbb2-dc29629258aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23 entries, 0 to 22\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   Weight  23 non-null     int64\n",
      " 1   Height  23 non-null     int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 496.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46d37ede-3909-4bd8-9edc-17b9f82d92c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weight    0\n",
       "Height    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbc6ea69-d6d2-4a9a-b27b-962096187739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>95</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Weight  Height\n",
       "11      95     182"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da63e2f3-011a-48bd-aaab-436f15e04443",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_duplicate = df.drop(df.index[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecbd7e27-9a12-44d7-8c65-e2c97f1d919d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight  Height\n",
       "0      45     120\n",
       "1      58     135\n",
       "2      48     123\n",
       "3      60     145\n",
       "4      70     160"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop_duplicate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "529c291c-f82d-4891-adc8-482bbec84e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent and dependent variable \n",
    "X = df[['Weight']]\n",
    "y = df['Height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64d45533-5cdb-4ea6-86b3-c72ca3e86097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23, 1), (23,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "afbda422-7423-4828-9f55-8e55bf52b10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1c793bb-0aab-4e0d-b2ad-7e51307c4b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9929357-5138-406d-8eeb-a1a8fe5c047a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41007671],\n",
       "       [-1.51215787],\n",
       "       [ 1.49934297],\n",
       "       [-1.70438132],\n",
       "       [-0.74326404],\n",
       "       [-0.10251918],\n",
       "       [ 0.28192774],\n",
       "       [-1.3840089 ],\n",
       "       [-0.99956198],\n",
       "       [ 0.02562979],\n",
       "       [ 1.17897054],\n",
       "       [ 0.66637465],\n",
       "       [ 0.85859811],\n",
       "       [ 0.98674708],\n",
       "       [ 0.53822568]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sclaed = scaler.fit_transform(X_train)\n",
    "X_train_sclaed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b20c694f-5c5d-462c-9f3b-46d2614cf914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41007671],\n",
       "       [ 0.41007671],\n",
       "       [-1.70438132],\n",
       "       [ 1.49934297],\n",
       "       [-0.42289161],\n",
       "       [ 2.14008783],\n",
       "       [-0.87141301],\n",
       "       [ 1.8197154 ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d3dab22d-22dc-4519-9dd9-f738d0c15716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a1810a0-c92f-453f-bf71-a9ef9a7deb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_sclaed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9b21877-80b2-45e7-9744-b9998c56fcec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([162.8051967 , 162.8051967 , 128.40340121, 180.52733377,\n",
       "       149.25297424, 190.95212028, 141.95562368, 185.73972703])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "y_pred = lr.predict(X_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a19250ee-5c36-4db4-a7fd-09a22eba3428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8074173081896224"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here I will perform r2 square\n",
    "from sklearn.metrics import r2_score\n",
    "score = r2_score(y_test,y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b50eaa9-63b6-4f4b-b88e-90f92fb3b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. Define adjusted R-squared and explain how it differs from the regular R-squared.\n",
    "Ans.\n",
    "Adjusted R-squared is like a smarter version of regular R-squared. While regular R-squared measures how well\n",
    "your model fits the data, adjusted R-squared considers the number of predictors in your model. It penalizes \n",
    "you if you add useless predictors that don't really improve your model. So, adjusted R-squared gives a more\n",
    "realistic picture of how effective your predictors are, helping you avoid the trap of thinking your model is\n",
    "better just because you added more variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb5e4c8-8375-4b2c-a25f-aae357b74ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. When is it more appropriate to use adjusted R-squared?\n",
    "Ans.\n",
    "Adjusted R-squared is more appropriate when you're comparing models with different numbers of predictors. It \n",
    "helps you see if adding more predictors is genuinely improving your model or if it's just making it look \n",
    "better without adding real value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d411ad-f68f-464d-a8e8-920cb7d05b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics\n",
    "# calculated, and what do they represent?\n",
    "Ans.\n",
    "1. Mean Squared Error (MSE):\n",
    "MSE is calculated by taking the average of the squared differences between the actual and predicted values. It\n",
    "penalizes large errors more heavily than small ones. The squared differences help in emphasizing and amplifying\n",
    "larger errors.\n",
    "\n",
    "Root Mean Squared Error (RMSE):\n",
    "RMSE is the square root of the MSE. It gives an error metric in the same unit as the dependent variable. RMSE is\n",
    "a more interpretable metric than MSE because it is on the same scale as the target variable. It provides a measure\n",
    "of how well the model is expected to perform in predicting the actual values.\n",
    "\n",
    "Mean Absolute Error (MAE):\n",
    "MAE is the average of the absolute differences between the actual and predicted values.MAE is less sensitive to \n",
    "outliers than MSE because it does not involve squaring. It gives an average of the absolute errors, providing a \n",
    "straightforward interpretation of the average magnitude of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6891f20c-b588-415d-abb0-887fe1948e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_Squared_Error : 91.42562383241722\n",
      "Mean_Absolute_Error : 8.332521348806658\n",
      "Root_Mean_Squared_Error 9.561674739940552\n"
     ]
    }
   ],
   "source": [
    "# Here I am calculated all the metrics on the behalf of previous Q1.\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print('Mean_Squared_Error :',mse)\n",
    "print('Mean_Absolute_Error :',mae)\n",
    "print('Root_Mean_Squared_Error',rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49977dc8-ee60-4b8f-b1a8-1df2df97ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in\n",
    "# regression analysis.\n",
    "Ans.\n",
    "Advantages and Disadvantages of RMSE, MSE, and MAE in Regression Analysis:\n",
    "\n",
    "1. Mean Squared Error (MSE):\n",
    "Advantages:\n",
    "MSE gives higher weight to larger errors, which can be beneficial if you want to strongly penalize \n",
    "significant deviations.\n",
    "It is differentiable, making it suitable for optimization algorithms.\n",
    "\n",
    "Disadvantages:\n",
    "The squared nature of MSE can amplify the impact of outliers, making the metric sensitive to extreme\n",
    "values.\n",
    "The unit of MSE is not the same as the target variable, which can make interpretation challenging.\n",
    "\n",
    "2. Root Mean Squared Error (RMSE):\n",
    "Advantages:\n",
    "RMSE is on the same scale as the dependent variable, providing a more interpretable measure of prediction\n",
    "error.\n",
    "It retains the emphasis on larger errors introduced by MSE.\n",
    "\n",
    "Disadvantages:\n",
    "Similar to MSE, RMSE is sensitive to outliers, and the squared nature can magnify their influence.\n",
    "It might not be suitable for all scenarios, especially when the goal is to reduce the impact of extreme values.\n",
    "\n",
    "3. Mean Absolute Error (MAE):\n",
    "Advantages:\n",
    "MAE is less sensitive to outliers since it uses absolute differences rather than squared differences.\n",
    "It provides a straightforward interpretation as the average magnitude of errors.\n",
    "The unit of MAE is the same as the target variable, facilitating easier understanding.\n",
    "\n",
    "Disadvantages:\n",
    "MAE does not penalize larger errors as heavily as MSE or RMSE, which might be a drawback if you want to emphasize\n",
    "the significance of larger deviations.\n",
    "The non-differentiability of the absolute function can be a limitation in certain optimization scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4dd0a6-cf46-40ec-a11d-205a499c57c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is\n",
    "# it more appropriate to use?\n",
    "Ans.\n",
    "Lasso regularization is like a coach for your regression model, encouraging it to be more efficient. It adds a penalty\n",
    "term to the traditional regression, pushing some of the less important features to have exactly zero coefficients. It's\n",
    "a way to simplify your model and select only the most essential predictors.\n",
    "\n",
    "Now, compared to its teammate Ridge regularization, Lasso is more ruthless. While both push for simplicity, Lasso can \n",
    "outright kick out variables by setting their coefficients to zero, unlike Ridge, which only shrinks them.\n",
    "\n",
    "So, when to use Lasso? Think of it as a hero when you suspect that some of your features are not that crucial and can be\n",
    "dropped from the team. If you want a sparse and straightforward model, Lasso might be your go-to regularization method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1c4e98-2bdd-45fd-a5d7-863ddedc9dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an\n",
    "# example to illustrate.\n",
    "Ans.\n",
    "Regularized linear models act like a coach guiding your model to avoid showing off too much. They add a penalty for \n",
    "complexity, preventing it from memorizing the training data too well, which can lead to overfitting. For example, imagine\n",
    "teaching a model to predict a student's grades. Without regularization, it might try too hard to fit the exact scores of \n",
    "each student in the training class, even the noisy ones. Regularization steps in like a sensible coach, saying, \"Okay, \n",
    "don't get too obsessed with these specific scores. Focus on the important patterns, and avoid trying to impress every single\n",
    "student's result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236b296d-928e-4623-9070-785fd54ec43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best\n",
    "# choice for regression analysis.\n",
    "Ans.\n",
    "Regularized linear models, while helpful, have their limits. They might not always be the Most important for regression\n",
    "analysis because:\n",
    "1. Loss of Important Features:\n",
    "Regularization can be too strict, kicking out variables, even important ones, by setting their coefficients to zero. This\n",
    "can lead to oversimplification and loss of valuable information.\n",
    "\n",
    "2. Model Complexity:\n",
    "These models might struggle with highly complex relationships in the data. If the underlying patterns are intricate, overly\n",
    "simplifying the model through regularization might not capture the nuances well.\n",
    "\n",
    "3. Parameter Sensitivity:\n",
    "The performance of regularized models depends on choosing the right regularization strength. Picking a value too high or too \n",
    "low can impact results. It's like finding the Goldilocks zone – not too much, not too little.\n",
    "\n",
    "4. Assumption of Linearity:\n",
    "Regularized linear models assume that relationships between variables are linear. If your data involves more complex, non-\n",
    "linear connections, these models might not be the best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd9d15-c455-4196-8ecd-b73557d8d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9. You are comparing the performance of two regression models using different evaluation metrics.\n",
    "# Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better\n",
    "# performer, and why? Are there any limitations to your choice of metric?\n",
    "Ans.\n",
    "RMSE of 10 (Model A): This metric penalizes larger errors more heavily due to the squared nature of the calculation. If\n",
    "minimizing large errors is crucial for my application, Model A might be preferable.\n",
    "\n",
    "MAE of 8 (Model B): This metric is less sensitive to outliers as it considers absolute differences. If prioritize a\n",
    "metric that gives equal weight to all errors, regardless of size, Model B could be a better choice.\n",
    "\n",
    "Absolutely! The choice of metric, whether it's RMSE or MAE, has its limitations. For example:\n",
    "1. Sensitivity to Outliers: Both metrics can be influenced by outliers, but in different ways. RMSE is more sensitive\n",
    "to large errors because it squares them, while MAE treats all errors equally.\n",
    "2. Scale Differences: RMSE and MAE are in different units than the original data. While RMSE is in the squared unit,\n",
    "MAE is in the original unit. This can affect how you interpret and communicate the results.\n",
    "3. Problem-specific Considerations: The \"best\" metric depends on the specific problem. Sometimes, what makes sense for \n",
    "one situation might not be suitable for another. Always consider the characteristics of your data and the goals of your \n",
    "analysis.\n",
    "4. Model Interpretability: RMSE might be less intuitive to interpret compared to MAE, especially for non-technical\n",
    "audiences. It's crucial to choose a metric that aligns with how you want to communicate the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223a9da3-16c3-4762-856a-d90b0b60a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10. You are comparing the performance of two regularized linear models using different types of\n",
    "# regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B\n",
    "# uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the\n",
    "# better performer, and why? Are there any trade-offs or limitations to your choice of regularization\n",
    "# method?\n",
    "Ans.\n",
    "Ridge (Model A, λ=0.1): Ridge is like a moderate coach, gently pushing the model to be efficient without completely\n",
    "kicking out features. It's good when we want to avoid overemphasizing any single variable and maintain most of our features.\n",
    "\n",
    "Lasso (Model B, λ=0.5): Lasso is a bit more ruthless. It not only encourages simplicity but might kick out less essential \n",
    "features by setting their coefficients to zero. It's handy when we suspect that some features aren't that crucial.\n",
    "\n",
    "Trade-offs and Considerations:\n",
    "1. Sparsity of Features: If having fewer, more essential features is crucial, Lasso (Model B) might be preferred due to its\n",
    "tendency to set some coefficients to zero.\n",
    "2. Variable Importance: Ridge (Model A) is gentler on features, so if we believe many variables are important to our outcome,\n",
    "Ridge could be better.\n",
    "3. Ridge for Multicollinearity: If our features are highly correlated (multicollinearity), Ridge is often more stable. Lasso \n",
    "might arbitrarily choose one of the correlated features and ignore the rest.\n",
    "4. Choice of Regularization Strength : The performance of both models heavily depends on choosing the right regularization\n",
    "strength. Too high or too low values might not yield optimal results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
